Simulating collapsibility
================
John Fee
2024-02-26

``` r
# I/O
library(here)

# Data manipulation
library(dplyr)
library(purrr)
library(tidyr)

# Graphics
library(ggplot2)
library(ggdag)
library(dagitty)
library(latex2exp)
theme_set(cowplot::theme_cowplot())

# Misc
source(here("R","sim-functions.R"))
set.seed(1)
```

We’re going to walk through a few different scenarios with different
data generating processes, and via simulation examine how well we can
recover the true value of the parameter of interest.

# A linear model

## Scenario 1 - No confounders

We measure the values of a continuous response variable $Y$, a binary
treatment variable $X$, and measured covariates $W$ and $Z$. $X$, $Y$,
and $Z$ are mutually independent, but $Y$ is dependent upon all of them.
We can represent this dependency structure graphically in the form of a
DAG.

``` r
dagify(
  Y ~ X,
  Y ~ W,
  Y ~ Z
) %>%
  ggdag() +
  theme_void()
```

<img src="Simulating-Collapsibility_files/figure-gfm/unnamed-chunk-2-1.png" style="display: block; margin: auto;" />

To simulate data compatible with this structure, I draw the predictors
from a multivariate normal distribution with a diagonal covariance
matrix (i.e. they are independent draws from separate normal
distributions). $X$ is thresholded to convert it into a binary variable,
and $Y$ is generated by the equation

$$
\begin{aligned}
  Y &= X + 3W + 1.5Z + \varepsilon\\
  \varepsilon &\sim \mathcal{N}(0,9)
\end{aligned}
$$

This process is repeated until 1000 datasets of size $n = 500$ are
generated. I then fit the same linear model to each simulated dataset,
and plot the distribution of the results and provide a table of summary
stats.

``` r
cov_matrix_diagonal <- matrix(
  c(
    4,0,0,
    0,4,0,
    0,0,4
  ),
  nrow = 3,
  ncol = 3,
  byrow = TRUE
)

results <- simulate_multiple_datasets(
  n = 500,
  sigma = cov_matrix_diagonal,
  y_formula = 3*W + X + 1.5*Z,
  n_simulations = 1000,
  x_threshold = qnorm(0.5), # Chosen so X is a 50/50 split in both treatment groups
  epsilon_sd = 9
) %>%
  mutate(
      fitted_model = map(data,~ lm(Y ~ X + Z + W,data = .x)),
      predicted_value = map2(.x = data,.y = fitted_model,.f = ~ predict(.y))
    )
```

``` r
coef_df <- data.frame(
  parameter = c("(Intercept)","X","Z","W"),
  true_value = c(0,1,1.5,3)
  ) %>%
  get_coef_df(results,.)

plot_coefficient_distribution(
  coef_df,
  title = "Distribution of linear regression parameter estimates \nfit on data simulated from the same linear model")
```

<img src="Simulating-Collapsibility_files/figure-gfm/unnamed-chunk-4-1.png" style="display: block; margin: auto;" />

``` r
coef_df %>%
  summarize_coef_df(caption = "Summary table for parameters of $n = 1000$ linear models fit on simulated data")
```

| Variable    | Parameter estimate | True value |       Bias |
|:------------|-------------------:|-----------:|-----------:|
| (Intercept) |          0.0023046 |        0.0 |  0.0023046 |
| W           |          2.9840192 |        3.0 | -0.0159808 |
| X           |          1.0034573 |        1.0 |  0.0034573 |
| Z           |          1.4959494 |        1.5 | -0.0040506 |

Summary table for parameters of $n = 1000$ linear models fit on
simulated data

As expected, the linear model provides unbiased estimates of the effect
associated with our treatment variable $X$. Varying the dataset size or
the amount of noise (variance of $\varepsilon$) would change the shape
of the simulated parameter distributions, but they would remain
unbiased. What if we have a more complicated dependency structure?

## Scenario 2 - Confounders present
